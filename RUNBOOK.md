# üöÄ RUNBOOK MASTER: Despliegue n8n Enterprise en AWS EKS

![Status](https://img.shields.io/badge/STATUS-PRODUCCI√ìN-success?style=for-the-badge&logo=checkmarx)
![Version](https://img.shields.io/badge/VERSION-5.0.0-blue?style=for-the-badge)
![FinOps](https://img.shields.io/badge/FINOPS-CERTIFIED-red?style=for-the-badge&logo=moneygram)
![AWS](https://img.shields.io/badge/AWS-EKS-FF9900?style=for-the-badge&logo=amazon-aws&logoColor=white)
![GitOps](https://img.shields.io/badge/GITOPS-ARGOCD-orange?style=for-the-badge&logo=argo)

**Autor:** Jose Garagorry & Gemini AI | **Nivel:** Enterprise Arch

**Prop√≥sito:** Este documento sirve como gu√≠a definitiva para el despliegue de una infraestructura GitOps escalable. Est√° dise√±ado para ser ejecutado de forma secuencial, garantizando que incluso un t√©cnico sin experiencia previa pueda levantar el entorno n8n Enterprise con persistencia de datos y conectividad p√∫blica en AWS.

---

## üìã Tabla de Contenidos
1. [Fase 0: Preparaci√≥n del Entorno](#fase-0-preparaci√≥n-del-entorno)
2. [Fase 1: Backend de Estado (Terragrunt)](#fase-1-backend-de-estado)
3. [Fase 2: Infraestructura de Red (VPC)](#fase-2-infraestructura-de-red-vpc)
4. [Fase 3: C√≥mputo (Cluster EKS)](#fase-3-c√≥mputo-cluster-eks)
5. [Fase 4: Plataforma (Identidad y Seguridad)](#fase-4-plataforma-identidad-y-seguridad)
6. [Fase 5: Tr√°fico y GitOps (ALB & ArgoCD)](#fase-5-tr√°fico-y-gitops)
7. [Fase 6: Despliegue de Aplicaci√≥n (GitOps n8n + DB)](#fase-6-despliegue-de-aplicaci√≥n-n8n)
8. [Fase 7: La Prueba de Fuego (Validaci√≥n Webhook)](#fase-7-la-prueba-de-fuego-webhook-test)
9. [Fase 8: Protocolo de Destrucci√≥n Forense](#fase-8-protocolo-de-destrucci√≥n-forense)

---

## üõ†Ô∏è Fase 0: Preparaci√≥n del Entorno
**Objetivo:** Instalar las herramientas necesarias para la gesti√≥n del cl√∫ster y la autenticaci√≥n con AWS.
```bash
# Instalaci√≥n de eksctl para gesti√≥n de OIDC e IAM Roles
curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
sudo mv /tmp/eksctl /usr/local/bin
eksctl version

# Verificaci√≥n de identidad
aws sts get-caller-identity
```

---

## üì¶ Fase 1: Backend de Estado
**Objetivo:** Configurar S3 y DynamoDB para el estado de Terragrunt.
```bash
./scripts/setup_backend.sh
./scripts/check_backend.sh
```

---

## üåê Fase 2: Infraestructura de Red (VPC)
```bash
cd iac/live/dev/vpc
terragrunt apply -auto-approve
```

---

## ‚ò∏Ô∏è Fase 3: C√≥mputo (Cluster EKS)
```bash
cd ../eks
terragrunt apply -auto-approve

# Actualizar kubeconfig
aws eks update-kubeconfig --name eks-gitops-dev --region us-east-1
```

---

## üèóÔ∏è Fase 4: Plataforma (Identidad y Seguridad)
**Objetivo:** Establecer la confianza (IRSA) para que los Pods gestionen recursos de AWS.

### 4.1: Activaci√≥n de OIDC
```bash
eksctl utils associate-iam-oidc-provider --cluster eks-gitops-dev --approve
```

### 4.2: Registro de Pol√≠tica de IAM
```bash
# Asegurarse de estar en la ra√≠z del proyecto para usar el archivo json
aws iam create-policy \
    --policy-name AWSLoadBalancerControllerIAMPolicy \
    --policy-document file://iam_policy.json
```

### 4.3: Creaci√≥n de Service Account (Identidad del Controlador)
```bash
eksctl create iamserviceaccount \
  --cluster=eks-gitops-dev \
  --region=us-east-1 \
  --namespace=kube-system \
  --name=aws-load-balancer-controller \
  --role-name AmazonEKSLoadBalancerControllerRole \
  --attach-policy-arn=arn:aws:iam::$(aws sts get-caller-identity --query Account --output text):policy/AWSLoadBalancerControllerIAMPolicy \
  --approve
```

---

## üö¶ Fase 5: Tr√°fico y GitOps (Controladores)
**Objetivo:** Instalar el software que materializa la infraestructura y el despliegue.

### 5.1: Instalaci√≥n del AWS Load Balancer Controller
```bash
helm repo add eks https://aws.github.io/eks-charts
helm repo update

helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
  -n kube-system \
  --set clusterName=eks-gitops-dev \
  --set serviceAccount.create=false \
  --set serviceAccount.name=aws-load-balancer-controller
```

### 5.2: Despliegue de ArgoCD
```bash
kubectl create namespace argocd
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml --server-side --force-conflicts
```

### 5.3: Acceso a la Consola ArgoCD

**Obtener Contrase√±a:**
```bash
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d; echo
```

**Iniciar T√∫nel:**
```bash
kubectl port-forward svc/argocd-server -n argocd 8080:443
```

**Acceso:** https://localhost:8080 (Usuario: admin)

---

## üöÄ Fase 6: Despliegue de Aplicaci√≥n (n8n Enterprise)

### 6.1: Preparaci√≥n del Entorno n8n
```bash
kubectl create namespace n8n-system
```

### 6.2: Despliegue de Base de Datos (PostgreSQL)
```bash
cat <<EOF > gitops/apps/database.yaml
apiVersion: v1
kind: Service
metadata:
  name: n8n-database-postgresql
  namespace: n8n-system
spec:
  ports:
    - port: 5432
  selector:
    app: n8n-postgres
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: n8n-postgres
  namespace: n8n-system
spec:
  selector:
    matchLabels:
      app: n8n-postgres
  template:
    metadata:
      labels:
        app: n8n-postgres
    spec:
      containers:
        - name: postgres
          image: postgres:13
          env:
            - name: POSTGRES_USER
              value: "n8n_user"
            - name: POSTGRES_PASSWORD
              value: "StrongPassword123!"
            - name: POSTGRES_DB
              value: "n8n_db"
          ports:
            - containerPort: 5432
EOF

kubectl apply -f gitops/apps/database.yaml
```

### 6.3: Despliegue de Motor n8n e Ingress

**Nota:** Hemos incluido `ingressClassName: alb` para asegurar la detecci√≥n inmediata por parte del controlador.
```bash
cat <<EOF > gitops/apps/n8n.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: n8n-ingress
  namespace: n8n-system
  annotations:
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip
    alb.ingress.kubernetes.io/healthcheck-path: /healthz
spec:
  ingressClassName: alb
  rules:
    - http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: n8n
                port:
                  number: 80
EOF

kubectl apply -f gitops/apps/n8n.yaml

# Verificaci√≥n de IP P√∫blica
kubectl get ingress -n n8n-system --watch
```

---

### üí° ¬øQu√© cambi√≥ para ser un Runbook "limpio"?

1. **Inclusi√≥n del Namespace:** El `kubectl create namespace n8n-system` ya es un paso formal en la Fase 6.1.
2. **IngressClassName nativo:** En lugar de parchar con `kubectl patch`, el comando `cat` de la Fase 6.3 ya incluye `ingressClassName: alb`. As√≠, el recurso nace configurado correctamente.
3. **Orden de Helm:** La Fase 5.1 garantiza que el controlador est√© listo **antes** de que intentes desplegar aplicaciones.

---

## üçí Fase 7: La Prueba de Fuego (Webhook Test)

1. Copie el ADDRESS del Ingress.
2. Cree un flujo en n8n con un nodo Webhook.
3. Reemplace localhost:5678 por el DNS de AWS y valide la respuesta JSON.

---

## üíÄ Fase 8: Protocolo de Destrucci√≥n Forense
```bash
./scripts/nuke_loadbalancers.sh

./scripts/clean_project_v2.sh

./scripts/nuke_backend_smart.sh

./scripts/audit_finops_extreme.sh
```

---

## üìù Notas Finales

Este runbook es una gu√≠a completa y secuencial para el despliegue de n8n Enterprise en AWS EKS con GitOps mediante ArgoCD. Sigue cada fase en orden para garantizar una implementaci√≥n exitosa.
