# üöÄ RUNBOOK MASTER: Despliegue n8n Enterprise en AWS EKS

![Status](https://img.shields.io/badge/STATUS-PRODUCCI√ìN-success?style=for-the-badge&logo=checkmarx)
![Version](https://img.shields.io/badge/VERSION-4.0.0-blue?style=for-the-badge)
![FinOps](https://img.shields.io/badge/FINOPS-CERTIFIED-red?style=for-the-badge&logo=moneygram)
![AWS](https://img.shields.io/badge/AWS-EKS-FF9900?style=for-the-badge&logo=amazon-aws&logoColor=white)
![GitOps](https://img.shields.io/badge/GITOPS-ARGOCD-orange?style=for-the-badge&logo=argo)

**Autor:** Jose Garagorry & Gemini AI | **Nivel:** Enterprise Arch

**Prop√≥sito:** Este documento sirve como gu√≠a definitiva para el despliegue de una infraestructura GitOps escalable. Est√° dise√±ado para ser ejecutado de forma secuencial, garantizando que incluso un t√©cnico sin experiencia previa pueda levantar el entorno n8n Enterprise con persistencia de datos y conectividad p√∫blica en AWS.

---

## üìã Tabla de Contenidos
1. [Fase 0: Preparaci√≥n del Entorno](#fase-0-preparaci√≥n-del-entorno)
2. [Fase 1: Backend de Estado (Terragrunt)](#fase-1-backend-de-estado)
3. [Fase 2: Infraestructura de Red (VPC)](#fase-2-infraestructura-de-red-vpc)
4. [Fase 3: C√≥mputo (Cluster EKS)](#fase-3-c√≥mputo-cluster-eks)
5. [Fase 4: Plataforma (Identidad, IAM y Tr√°fico)](#fase-4-plataforma-identidad-y-tr√°fico)
6. [Fase 5: Despliegue de Aplicaci√≥n (GitOps n8n + DB)](#fase-5-despliegue-de-aplicaci√≥n-n8n)
7. [Fase 6: La Prueba de Fuego (Validaci√≥n Webhook)](#fase-6-la-prueba-de-fuego-webhook-test)
8. [Fase 7: Protocolo de Destrucci√≥n Forense](#fase-7-protocolo-de-destrucci√≥n-forense)

---

## üõ†Ô∏è Fase 0: Preparaci√≥n del Entorno
**Objetivo:** Instalar las herramientas necesarias para la gesti√≥n del cl√∫ster y la autenticaci√≥n con AWS.

* **eksctl:** Herramienta oficial para gestionar cl√∫steres EKS y proveedores de identidad OIDC.
* **aws-cli:** Interfaz de comandos para interactuar con los servicios de Amazon.

```bash
# Instalaci√≥n de eksctl para gesti√≥n de OIDC e IAM Roles
curl --silent --location "[https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname](https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname) -s)_amd64.tar.gz" | tar xz -C /tmp
sudo mv /tmp/eksctl /usr/local/bin

# Verificaci√≥n de identidad para asegurar que tenemos permisos de administrador
aws sts get-caller-identity
```

---

## üì¶ Fase 1: Backend de Estado
**Objetivo:** Configurar S3 y DynamoDB para que Terragrunt pueda almacenar el estado de la infraestructura de forma segura y evitar conflictos de bloqueo.

```bash
./scripts/setup_backend.sh
./scripts/check_backend.sh
```

---

## üåê Fase 2: Infraestructura de Red (VPC)
**Objetivo:** Crear la red segmentada (VPC) con subredes p√∫blicas y privadas, NAT Gateways y tablas de ruteo necesarias para el tr√°fico del cl√∫ster.

```bash
cd iac/live/dev/vpc
terragrunt apply -auto-approve
```

---

## ‚ò∏Ô∏è Fase 3: C√≥mputo (Cluster EKS)
**Objetivo:** Desplegar el cl√∫ster de Kubernetes (EKS) y los nodos de trabajo donde correr√°n nuestros contenedores.

```bash
cd ../eks
terragrunt apply -auto-approve

# Actualizar el archivo kubeconfig local para poder comandar el cl√∫ster con kubectl
aws eks update-kubeconfig --name eks-gitops-dev --region us-east-1
```

---

## üèóÔ∏è Fase 4: Plataforma (Identidad y Tr√°fico)
**Objetivo:** Configurar la seguridad de identidad (OIDC) y los permisos de IAM para que el cl√∫ster pueda crear recursos en AWS autom√°ticamente (como el Load Balancer).

### 4.1: Vinculaci√≥n OIDC
```bash
eksctl utils associate-iam-oidc-provider --cluster eks-gitops-dev --approve
```

### 4.2: Inyecci√≥n de Permisos IAM (Paso Cr√≠tico)
**Vital:** Sin este paso, el controlador de AWS Load Balancer no tendr√° permiso para crear el balanceador f√≠sico. Esto soluciona el error donde el Ingress se queda sin direcci√≥n IP (ADDRESS vac√≠o).

```bash
cd ../../../
# Descargar la pol√≠tica oficial de Amazon para el Load Balancer Controller
curl -o iam_policy.json [https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/main/docs/install/iam_policy.json](https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/main/docs/install/iam_policy.json)

# Adjuntar la pol√≠tica al rol de IAM del controlador
aws iam put-role-policy --role-name AmazonEKSLoadBalancerControllerRole --policy-name ALBControllerPolicy --policy-document file://iam_policy.json
```

### 4.3: Acceso a Consola GitOps (ArgoCD)
**Objetivo:** Monitorear visualmente la salud de las aplicaciones.
1.  **Obtener Contrase√±a Admin:**
    ```bash
    kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d; echo
    ```
2.  **Habilitar T√∫nel (Port-Forward):**
    ```bash
    kubectl port-forward svc/argocd-server -n argocd 8080:443
    ```
3.  **URL de Acceso:** Abra `https://localhost:8080` e ingrese con usuario `admin`.

---

## üöÄ Fase 5: Despliegue de Aplicaci√≥n (Full GitOps)
**Objetivo:** Desplegar n8n y su base de datos PostgreSQL de forma que ArgoCD las reconozca y gestione por separado.

### 5.1: Base de Datos (PostgreSQL) - Persistencia
**Inyecci√≥n de configuraci√≥n validada (User: n8n_user / Pass: StrongPassword123!).**
Este comando utiliza `<<EOF` para garantizar que todo el contenido del manifiesto se escriba correctamente en el archivo local.

```bash
cat <<EOF > gitops/apps/database.yaml
apiVersion: v1
kind: Service
metadata:
  name: n8n-database-postgresql
  namespace: n8n-system
spec:
  ports:
    - port: 5432
  selector:
    app: n8n-postgres
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: n8n-postgres
  namespace: n8n-system
spec:
  selector:
    matchLabels:
      app: n8n-postgres
  template:
    metadata:
      labels:
        app: n8n-postgres
    spec:
      containers:
        - name: postgres
          image: postgres:13
          env:
            - name: POSTGRES_USER
              value: "n8n_user"
            - name: POSTGRES_PASSWORD
              value: "StrongPassword123!"
            - name: POSTGRES_DB
              value: "n8n_db"
          ports:
            - containerPort: 5432
EOF
# Aplicar la base de datos para inicializar el servicio en el cl√∫ster
kubectl apply -f gitops/apps/database.yaml
```

### 5.2: Registro en ArgoCD (Doble Visualizaci√≥n)
**IMPORTANTE:** Este paso crea un objeto tipo `Application` dentro de ArgoCD. Esto permite que la base de datos aparezca como una "tarjeta" independiente en el panel visual, facilitando su monitoreo y sincronizaci√≥n.

```bash
kubectl apply -f - <<EOF
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: n8n-database
  namespace: argocd
spec:
  project: default
  source:
    repoURL: '[https://github.com/jgaragorry/aws-eks-n8n-enterprise.git](https://github.com/jgaragorry/aws-eks-n8n-enterprise.git)'
    targetRevision: HEAD
    path: gitops/apps
    directory:
      include: 'database.yaml'
  destination:
    server: '[https://kubernetes.default.svc](https://kubernetes.default.svc)'
    namespace: n8n-system
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
EOF
```

### 5.3: Despliegue de Motor n8n
```bash
kubectl apply -f gitops/apps/n8n.yaml
# Monitorear la creaci√≥n del balanceador de carga externo
kubectl get ingress -n n8n-system --watch
```

---

## üçí Fase 6: La Prueba de Fuego (Webhook Test)
**Objetivo:** Validar la comunicaci√≥n entre el balanceador de AWS (ALB), el Pod de n8n y la base de datos PostgreSQL.

### 1. Acceso
Copie el DNS generado en la Fase 5 (columna ADDRESS) y √°bralo en su navegador.

### 2. Creaci√≥n del Workflow de Validaci√≥n
- Haga clic en **"Create your first workflow"**.
- A√±ada un nodo **Webhook** (configurado como GET).
- A√±ada un nodo **Respond to Webhook**. En **"Response Body"**, seleccione JSON y pegue:
```json
  {"mensaje": "¬°Hola Jose! Cluster VIVO ü§ñüöÄ", "db_status": "connected", "gitops": "active"}
```

### 3. Ejecuci√≥n y Validaci√≥n Real
- Presione **"Execute Workflow"**.
- Copie la **"Test URL"** generada por el nodo Webhook.
- **IMPORTANTE:** El sistema generar√° una URL con `localhost:5678`. Debe reemplazar esa parte por su **DNS ADDRESS de AWS**.
- Si visualiza el JSON en el navegador, el tr√°fico fluye por el Ingress y n8n est√° operando con normalidad.

---

## üíÄ Fase 7: Protocolo de Destrucci√≥n Forense
**Objetivo:** Limpieza total y garantizada de recursos para llevar el costo de AWS a $0.00. 

> [!IMPORTANT]
> El orden de ejecuci√≥n es cr√≠tico para evitar recursos hu√©rfanos que impiden el borrado de la VPC.

```bash
# 1. ELIMINACI√ìN DE TR√ÅFICO (Capa 7)
# Elimina el Ingress para que AWS empiece a liberar el Load Balancer (ALB)
kubectl delete ingress --all -A

# 2. LIMPIEZA DE IDENTIDADES Y LOGS (FinOps)
# Borra logs de CloudWatch y roles IAM manuales detectados por la auditor√≠a
./scripts/nuke_zombies.sh

# 3. DESTRUCCI√ìN DE C√ìMPUTO (Capa 4)
# Elimina los nodos de trabajo y el cl√∫ster EKS
cd iac/live/dev/eks
terragrunt destroy -auto-approve

# 4. DESTRUCCI√ìN DE RED (Capa 2-3)
# Elimina la VPC, NAT Gateway y Elastic IPs (Solo tras borrar el EKS)
cd ../vpc
terragrunt destroy -auto-approve

# 5. ELIMINACI√ìN DE ESTADO (Cerebro de Infra)
# Elimina el Bucket S3 y la Tabla DynamoDB de Terraform
cd ../../../
./scripts/nuke_backend_smart.sh

# 6. AUDITOR√çA FINAL DE CONFIRMACI√ìN
# Ejecuta el bloque de auditor√≠a para certificar el estado $0.00
./scripts/audit_finops_extreme.sh && ./scripts/audit_finops_ultimate.sh
```
---
**Estado Final Esperado:** COSTO AWS = $0.00 üèÅ
